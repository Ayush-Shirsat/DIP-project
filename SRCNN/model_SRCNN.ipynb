{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import SGD,RMSprop,Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Disable warning message of tensorflow\n",
    "import cv2\n",
    "from numpy import *\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.util.shape import view_as_windows\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396900\n"
     ]
    }
   ],
   "source": [
    "# Load X data\n",
    "path1 = './Input/'\n",
    "X_data = os.listdir(path1)\n",
    "X_data = sorted(X_data)\n",
    "\n",
    "X = []\n",
    "window_shape = (32, 32)\n",
    "for img in X_data:\n",
    "    im = cv2.imread(path1 + img,0)\n",
    "    patches = view_as_windows(im, window_shape, step=16)\n",
    "    patches = patches.reshape(patches.shape[0]*patches.shape[1],32,32)\n",
    "    for i in range(0,len(patches)):\n",
    "        X.append(patches[i])\n",
    "        \n",
    "X = np.array(X)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396900\n"
     ]
    }
   ],
   "source": [
    "# Load Y data\n",
    "path2 = './Label/'\n",
    "Y_data = os.listdir(path2)\n",
    "Y_data = sorted(Y_data)\n",
    "\n",
    "Y = []\n",
    "window_shape = (32, 32)\n",
    "for img2 in Y_data:\n",
    "    im2 = cv2.imread(path2 + img2,0)\n",
    "    patches = view_as_windows(im2, window_shape, step=16)\n",
    "    patches = patches.reshape(patches.shape[0]*patches.shape[1],32,32)\n",
    "    for i in range(0,len(patches)):\n",
    "        Y.append(patches[i])\n",
    "\n",
    "Y = np.array(Y)\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317520, 32, 32, 1) (79380, 32, 32, 1) (317520, 32, 32, 1) (79380, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 4)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 1)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 32, 32, 1)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0], 32, 32, 1)\n",
    "\n",
    "X_train = X_train.astype('int') \n",
    "X_test = X_test.astype('int')\n",
    "Y_train = Y_train.astype('int') \n",
    "Y_test = Y_test.astype('int')\n",
    "\n",
    "# Normalization of data \n",
    "# Data pixels are between 0 and 1\n",
    "# X_train /= 255\n",
    "# X_test /= 255\n",
    "# Y_train /= 255\n",
    "# Y_test /= 255\n",
    "\n",
    "print(np.shape(X_train),np.shape(X_test),np.shape(Y_train),np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /share/pkg/python/3.6.2/install/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       10496     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 1)         1601      \n",
      "=================================================================\n",
      "Total params: 20,353\n",
      "Trainable params: 20,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, (9, 9), activation='relu', padding='same', input_shape=(32, 32, 1)))\n",
    "model.add(Conv2D(64, (1, 1), activation='relu', padding='same'))\n",
    "model.add(Conv2D(1, (5, 5), activation='linear', padding='same'))\n",
    "\n",
    "opt = Adam(lr = 0.01)\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer = opt) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 254016 samples, validate on 63504 samples\n",
      "Epoch 1/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 11.9142Epoch 00000: loss improved from inf to 11.89934, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 24s - loss: 11.8993 - val_loss: 6.1865\n",
      "Epoch 2/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.9733Epoch 00001: loss improved from 11.89934 to 5.97156, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 5.9716 - val_loss: 6.2259\n",
      "Epoch 3/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 6.0006Epoch 00002: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 5.9992 - val_loss: 5.0646\n",
      "Epoch 4/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.4114Epoch 00003: loss improved from 5.97156 to 5.41065, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 5.4107 - val_loss: 5.4576\n",
      "Epoch 5/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.5613Epoch 00004: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.5620 - val_loss: 5.0239\n",
      "Epoch 6/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.4621Epoch 00005: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.4634 - val_loss: 5.0554\n",
      "Epoch 7/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.7390Epoch 00006: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.7398 - val_loss: 4.9945\n",
      "Epoch 8/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.2594Epoch 00007: loss improved from 5.41065 to 5.25872, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 5.2587 - val_loss: 5.4582\n",
      "Epoch 9/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.2484Epoch 00008: loss improved from 5.25872 to 5.24744, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 5.2474 - val_loss: 4.9131\n",
      "Epoch 10/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.9140Epoch 00009: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.9116 - val_loss: 5.7692\n",
      "Epoch 11/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.2319Epoch 00010: loss improved from 5.24744 to 5.23150, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 5.2315 - val_loss: 6.3324\n",
      "Epoch 12/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.1849Epoch 00011: loss improved from 5.23150 to 5.18497, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 5.1850 - val_loss: 5.4881\n",
      "Epoch 13/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.2071Epoch 00012: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.2072 - val_loss: 5.2928\n",
      "Epoch 14/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.4369Epoch 00013: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.4354 - val_loss: 5.1603\n",
      "Epoch 15/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.0271Epoch 00014: loss improved from 5.18497 to 5.02768, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 5.0277 - val_loss: 5.0517\n",
      "Epoch 16/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.1484Epoch 00015: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.1476 - val_loss: 5.6560\n",
      "Epoch 17/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.0775Epoch 00016: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.0772 - val_loss: 5.1868\n",
      "Epoch 18/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.0843Epoch 00017: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.0854 - val_loss: 5.0622\n",
      "Epoch 19/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.7777Epoch 00018: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.7764 - val_loss: 6.8548\n",
      "Epoch 20/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.0716Epoch 00019: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.0712 - val_loss: 4.9526\n",
      "Epoch 21/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.2472Epoch 00020: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.2473 - val_loss: 5.5907\n",
      "Epoch 22/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.1469Epoch 00021: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.1467 - val_loss: 4.7735\n",
      "Epoch 23/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.2138Epoch 00022: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.2140 - val_loss: 5.1813\n",
      "Epoch 24/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.0350Epoch 00023: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.0354 - val_loss: 5.1342\n",
      "Epoch 25/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.9831Epoch 00024: loss improved from 5.02768 to 4.98305, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.9831 - val_loss: 5.1685\n",
      "Epoch 26/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.9691Epoch 00025: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.9696 - val_loss: 6.8481\n",
      "Epoch 27/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.7144Epoch 00026: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.7122 - val_loss: 4.8186\n",
      "Epoch 28/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.8441Epoch 00027: loss improved from 4.98305 to 4.84392, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.8439 - val_loss: 4.7639\n",
      "Epoch 29/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.9417Epoch 00028: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.9426 - val_loss: 5.2711\n",
      "Epoch 30/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.9430Epoch 00029: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.9426 - val_loss: 6.7181\n",
      "Epoch 31/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.1104Epoch 00030: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.1108 - val_loss: 4.8429\n",
      "Epoch 32/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.1220Epoch 00031: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.1227 - val_loss: 4.8423\n",
      "Epoch 33/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.9712Epoch 00032: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.9716 - val_loss: 5.5801\n",
      "Epoch 34/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 5.0023Epoch 00033: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 5.0017 - val_loss: 4.8837\n",
      "Epoch 35/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.9321Epoch 00034: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.9321 - val_loss: 4.8634\n",
      "Epoch 36/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.9446Epoch 00035: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.9451 - val_loss: 4.7477\n",
      "Epoch 37/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.9886Epoch 00036: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.9886 - val_loss: 5.2301\n",
      "Epoch 38/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.9483Epoch 00037: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.9480 - val_loss: 5.2442\n",
      "Epoch 39/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.9007Epoch 00038: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.9006 - val_loss: 5.1046\n",
      "Epoch 40/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6889Epoch 00039: loss improved from 4.84392 to 4.68880, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6888 - val_loss: 4.7206\n",
      "Epoch 41/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6806Epoch 00040: loss improved from 4.68880 to 4.68072, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6807 - val_loss: 4.7152\n",
      "Epoch 42/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6783Epoch 00041: loss improved from 4.68072 to 4.67852, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6785 - val_loss: 4.7110\n",
      "Epoch 43/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6758Epoch 00042: loss improved from 4.67852 to 4.67638, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6764 - val_loss: 4.7077\n",
      "Epoch 44/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6747Epoch 00043: loss improved from 4.67638 to 4.67438, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6744 - val_loss: 4.7144\n",
      "Epoch 45/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6736Epoch 00044: loss improved from 4.67438 to 4.67411, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6741 - val_loss: 4.7059\n",
      "Epoch 46/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6730Epoch 00045: loss improved from 4.67411 to 4.67308, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6731 - val_loss: 4.6999\n",
      "Epoch 47/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6687Epoch 00046: loss improved from 4.67308 to 4.66820, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6682 - val_loss: 4.6983\n",
      "Epoch 48/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6645Epoch 00047: loss improved from 4.66820 to 4.66413, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6641 - val_loss: 4.7401\n",
      "Epoch 49/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6604Epoch 00048: loss improved from 4.66413 to 4.66075, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6607 - val_loss: 4.6882\n",
      "Epoch 50/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6572Epoch 00049: loss improved from 4.66075 to 4.65702, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6570 - val_loss: 4.6886\n",
      "Epoch 51/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6566Epoch 00050: loss improved from 4.65702 to 4.65696, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6570 - val_loss: 4.6818\n",
      "Epoch 52/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6523Epoch 00051: loss improved from 4.65696 to 4.65241, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6524 - val_loss: 4.7022\n",
      "Epoch 53/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6512Epoch 00052: loss improved from 4.65241 to 4.65119, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6512 - val_loss: 4.6731\n",
      "Epoch 54/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6397Epoch 00053: loss improved from 4.65119 to 4.64016, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6402 - val_loss: 4.6632\n",
      "Epoch 55/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6313Epoch 00054: loss improved from 4.64016 to 4.63097, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.6310 - val_loss: 4.6556\n",
      "Epoch 56/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6273Epoch 00055: loss improved from 4.63097 to 4.62715, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6272 - val_loss: 4.6792\n",
      "Epoch 57/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6265Epoch 00056: loss improved from 4.62715 to 4.62667, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6267 - val_loss: 4.6521\n",
      "Epoch 58/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6199Epoch 00057: loss improved from 4.62667 to 4.62003, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6200 - val_loss: 4.6491\n",
      "Epoch 59/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6193Epoch 00058: loss improved from 4.62003 to 4.61933, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6193 - val_loss: 4.6683\n",
      "Epoch 60/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6195Epoch 00059: loss improved from 4.61933 to 4.61913, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6191 - val_loss: 4.7038\n",
      "Epoch 61/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6158Epoch 00060: loss improved from 4.61913 to 4.61566, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6157 - val_loss: 4.7331\n",
      "Epoch 62/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6134Epoch 00061: loss improved from 4.61566 to 4.61367, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.6137 - val_loss: 4.6445\n",
      "Epoch 63/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.6048Epoch 00062: loss improved from 4.61367 to 4.60458, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.6046 - val_loss: 4.6766\n",
      "Epoch 64/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5990Epoch 00063: loss improved from 4.60458 to 4.59871, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5987 - val_loss: 4.6229\n",
      "Epoch 65/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5955Epoch 00064: loss improved from 4.59871 to 4.59561, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5956 - val_loss: 4.6549\n",
      "Epoch 66/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5929Epoch 00065: loss improved from 4.59561 to 4.59282, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5928 - val_loss: 4.6391\n",
      "Epoch 67/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5900Epoch 00066: loss improved from 4.59282 to 4.58997, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5900 - val_loss: 4.7185\n",
      "Epoch 68/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5889Epoch 00067: loss improved from 4.58997 to 4.58923, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5892 - val_loss: 4.6136\n",
      "Epoch 69/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5837Epoch 00068: loss improved from 4.58923 to 4.58358, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.5836 - val_loss: 4.6081\n",
      "Epoch 70/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5770Epoch 00069: loss improved from 4.58358 to 4.57767, saving model to weights.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254016/254016 [==============================] - 22s - loss: 4.5777 - val_loss: 4.6286\n",
      "Epoch 71/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5770Epoch 00070: loss improved from 4.57767 to 4.57673, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5767 - val_loss: 4.5988\n",
      "Epoch 72/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5749Epoch 00071: loss improved from 4.57673 to 4.57503, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5750 - val_loss: 4.6056\n",
      "Epoch 73/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5683Epoch 00072: loss improved from 4.57503 to 4.56860, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5686 - val_loss: 4.5934\n",
      "Epoch 74/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5673Epoch 00073: loss improved from 4.56860 to 4.56742, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5674 - val_loss: 4.6347\n",
      "Epoch 75/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5689Epoch 00074: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5690 - val_loss: 4.6266\n",
      "Epoch 76/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5674Epoch 00075: loss improved from 4.56742 to 4.56730, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5673 - val_loss: 4.5907\n",
      "Epoch 77/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5646Epoch 00076: loss improved from 4.56730 to 4.56487, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5649 - val_loss: 4.6088\n",
      "Epoch 78/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5646Epoch 00077: loss improved from 4.56487 to 4.56425, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5642 - val_loss: 4.5899\n",
      "Epoch 79/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5626Epoch 00078: loss improved from 4.56425 to 4.56295, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5630 - val_loss: 4.6362\n",
      "Epoch 80/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5613Epoch 00079: loss improved from 4.56295 to 4.56150, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5615 - val_loss: 4.5863\n",
      "Epoch 81/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5584Epoch 00080: loss improved from 4.56150 to 4.55881, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5588 - val_loss: 4.5836\n",
      "Epoch 82/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5589Epoch 00081: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5590 - val_loss: 4.5847\n",
      "Epoch 83/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5593Epoch 00082: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.5598 - val_loss: 4.5861\n",
      "Epoch 84/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5615Epoch 00083: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5615 - val_loss: 4.5816\n",
      "Epoch 85/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5560Epoch 00084: loss improved from 4.55881 to 4.55643, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5564 - val_loss: 4.6334\n",
      "Epoch 86/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5571Epoch 00085: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5566 - val_loss: 4.5784\n",
      "Epoch 87/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5561Epoch 00086: loss improved from 4.55643 to 4.55576, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5558 - val_loss: 4.5823\n",
      "Epoch 88/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5528Epoch 00087: loss improved from 4.55576 to 4.55282, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5528 - val_loss: 4.5775\n",
      "Epoch 89/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5513Epoch 00088: loss improved from 4.55282 to 4.55162, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5516 - val_loss: 4.5753\n",
      "Epoch 90/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5516Epoch 00089: loss improved from 4.55162 to 4.55098, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5510 - val_loss: 4.5931\n",
      "Epoch 91/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5509Epoch 00090: loss improved from 4.55098 to 4.55027, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5503 - val_loss: 4.5756\n",
      "Epoch 92/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5491Epoch 00091: loss improved from 4.55027 to 4.54879, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5488 - val_loss: 4.5751\n",
      "Epoch 93/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5465Epoch 00092: loss improved from 4.54879 to 4.54675, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5467 - val_loss: 4.5872\n",
      "Epoch 94/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5486Epoch 00093: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5486 - val_loss: 4.5712\n",
      "Epoch 95/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5450Epoch 00094: loss improved from 4.54675 to 4.54486, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5449 - val_loss: 4.5691\n",
      "Epoch 96/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5448Epoch 00095: loss improved from 4.54486 to 4.54454, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5445 - val_loss: 4.6358\n",
      "Epoch 97/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5410Epoch 00096: loss improved from 4.54454 to 4.54090, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5409 - val_loss: 4.5687\n",
      "Epoch 98/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5401Epoch 00097: loss improved from 4.54090 to 4.54002, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5400 - val_loss: 4.5732\n",
      "Epoch 99/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5441Epoch 00098: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5444 - val_loss: 4.5939\n",
      "Epoch 100/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5394Epoch 00099: loss improved from 4.54002 to 4.53913, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5391 - val_loss: 4.5743\n",
      "Epoch 101/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5408Epoch 00100: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5409 - val_loss: 4.7071\n",
      "Epoch 102/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5400Epoch 00101: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5399 - val_loss: 4.5654\n",
      "Epoch 103/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5374Epoch 00102: loss improved from 4.53913 to 4.53730, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5373 - val_loss: 4.5623\n",
      "Epoch 104/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5353Epoch 00103: loss improved from 4.53730 to 4.53489, saving model to weights.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254016/254016 [==============================] - 21s - loss: 4.5349 - val_loss: 4.5624\n",
      "Epoch 105/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5326Epoch 00104: loss improved from 4.53489 to 4.53238, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.5324 - val_loss: 4.5706\n",
      "Epoch 106/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5353Epoch 00105: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5353 - val_loss: 4.5578\n",
      "Epoch 107/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5330Epoch 00106: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5331 - val_loss: 4.5737\n",
      "Epoch 108/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5331Epoch 00107: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.5331 - val_loss: 4.5814\n",
      "Epoch 109/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5282Epoch 00108: loss improved from 4.53238 to 4.52784, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.5278 - val_loss: 4.5573\n",
      "Epoch 110/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5272Epoch 00109: loss improved from 4.52784 to 4.52714, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5271 - val_loss: 4.5589\n",
      "Epoch 111/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5296Epoch 00110: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.5294 - val_loss: 4.5580\n",
      "Epoch 112/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5249Epoch 00111: loss improved from 4.52714 to 4.52509, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5251 - val_loss: 4.5534\n",
      "Epoch 113/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5288Epoch 00112: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5289 - val_loss: 4.5533\n",
      "Epoch 114/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5244Epoch 00113: loss improved from 4.52509 to 4.52459, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5246 - val_loss: 4.5549\n",
      "Epoch 115/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5242Epoch 00114: loss improved from 4.52459 to 4.52384, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5238 - val_loss: 4.5523\n",
      "Epoch 116/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5259Epoch 00115: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5259 - val_loss: 4.5607\n",
      "Epoch 117/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5239Epoch 00116: loss improved from 4.52384 to 4.52367, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5237 - val_loss: 4.6533\n",
      "Epoch 118/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5227Epoch 00117: loss improved from 4.52367 to 4.52306, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.5231 - val_loss: 4.6844\n",
      "Epoch 119/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5232Epoch 00118: loss improved from 4.52306 to 4.52305, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5230 - val_loss: 4.5580\n",
      "Epoch 120/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5223Epoch 00119: loss improved from 4.52305 to 4.52172, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5217 - val_loss: 4.5612\n",
      "Epoch 121/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5216Epoch 00120: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5218 - val_loss: 4.5932\n",
      "Epoch 122/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5206Epoch 00121: loss improved from 4.52172 to 4.52073, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5207 - val_loss: 4.5502\n",
      "Epoch 123/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5188Epoch 00122: loss improved from 4.52073 to 4.51894, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5189 - val_loss: 4.5629\n",
      "Epoch 124/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5162Epoch 00123: loss improved from 4.51894 to 4.51599, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5160 - val_loss: 4.5501\n",
      "Epoch 125/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5167Epoch 00124: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5165 - val_loss: 4.5526\n",
      "Epoch 126/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5158Epoch 00125: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5161 - val_loss: 4.5485\n",
      "Epoch 127/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5193Epoch 00126: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5197 - val_loss: 4.5531\n",
      "Epoch 128/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5136Epoch 00127: loss improved from 4.51599 to 4.51365, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.5136 - val_loss: 4.5915\n",
      "Epoch 129/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5148Epoch 00128: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5148 - val_loss: 4.5438\n",
      "Epoch 130/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5119Epoch 00129: loss improved from 4.51365 to 4.51214, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5121 - val_loss: 4.5414\n",
      "Epoch 131/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5141Epoch 00130: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5145 - val_loss: 4.5382\n",
      "Epoch 132/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5163Epoch 00131: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5162 - val_loss: 4.5540\n",
      "Epoch 133/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5169Epoch 00132: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5167 - val_loss: 4.5821\n",
      "Epoch 134/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5140Epoch 00133: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5142 - val_loss: 4.5797\n",
      "Epoch 135/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5110Epoch 00134: loss improved from 4.51214 to 4.51066, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5107 - val_loss: 4.5855\n",
      "Epoch 136/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5075Epoch 00135: loss improved from 4.51066 to 4.50810, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5081 - val_loss: 4.5687\n",
      "Epoch 137/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5098Epoch 00136: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5097 - val_loss: 4.5617\n",
      "Epoch 138/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5138Epoch 00137: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5136 - val_loss: 4.5429\n",
      "Epoch 139/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5065Epoch 00138: loss improved from 4.50810 to 4.50659, saving model to weights.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254016/254016 [==============================] - 22s - loss: 4.5066 - val_loss: 4.5355\n",
      "Epoch 140/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5094Epoch 00139: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5094 - val_loss: 4.5340\n",
      "Epoch 141/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5046Epoch 00140: loss improved from 4.50659 to 4.50512, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.5051 - val_loss: 4.5315\n",
      "Epoch 142/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5068Epoch 00141: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.5071 - val_loss: 4.5535\n",
      "Epoch 143/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5080Epoch 00142: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5082 - val_loss: 4.5425\n",
      "Epoch 144/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5027Epoch 00143: loss improved from 4.50512 to 4.50324, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.5032 - val_loss: 4.6919\n",
      "Epoch 145/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5077Epoch 00144: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5074 - val_loss: 4.5360\n",
      "Epoch 146/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5024Epoch 00145: loss improved from 4.50324 to 4.50260, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.5026 - val_loss: 4.5310\n",
      "Epoch 147/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5061Epoch 00146: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5062 - val_loss: 4.5477\n",
      "Epoch 148/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5047Epoch 00147: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5047 - val_loss: 4.5365\n",
      "Epoch 149/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5040Epoch 00148: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5042 - val_loss: 4.5629\n",
      "Epoch 150/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5032Epoch 00149: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5032 - val_loss: 4.5388\n",
      "Epoch 151/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5039Epoch 00150: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5036 - val_loss: 4.5461\n",
      "Epoch 152/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5056Epoch 00151: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5055 - val_loss: 4.5709\n",
      "Epoch 153/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5010Epoch 00152: loss improved from 4.50260 to 4.50082, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.5008 - val_loss: 4.5280\n",
      "Epoch 154/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5028Epoch 00153: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.5027 - val_loss: 4.5292\n",
      "Epoch 155/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5021Epoch 00154: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5025 - val_loss: 4.6174\n",
      "Epoch 156/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5014Epoch 00155: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5014 - val_loss: 4.5316\n",
      "Epoch 157/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5035Epoch 00156: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5034 - val_loss: 4.5438\n",
      "Epoch 158/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5033Epoch 00157: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.5030 - val_loss: 4.5356\n",
      "Epoch 159/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5022Epoch 00158: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5021 - val_loss: 4.5285\n",
      "Epoch 160/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5004Epoch 00159: loss improved from 4.50082 to 4.50036, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.5004 - val_loss: 4.5355\n",
      "Epoch 161/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4991Epoch 00160: loss improved from 4.50036 to 4.49919, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4992 - val_loss: 4.5555\n",
      "Epoch 162/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5009Epoch 00161: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5009 - val_loss: 4.5439\n",
      "Epoch 163/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.5012Epoch 00162: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.5009 - val_loss: 4.5276\n",
      "Epoch 164/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4955Epoch 00163: loss improved from 4.49919 to 4.49558, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4956 - val_loss: 4.5261\n",
      "Epoch 165/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4976Epoch 00164: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4977 - val_loss: 4.5301\n",
      "Epoch 166/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4966Epoch 00165: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4965 - val_loss: 4.5222\n",
      "Epoch 167/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4965Epoch 00166: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4967 - val_loss: 4.5267\n",
      "Epoch 168/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4949Epoch 00167: loss improved from 4.49558 to 4.49442, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4944 - val_loss: 4.5228\n",
      "Epoch 169/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4975Epoch 00168: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4974 - val_loss: 4.5599\n",
      "Epoch 170/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4996Epoch 00169: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4999 - val_loss: 4.5323\n",
      "Epoch 171/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4937Epoch 00170: loss improved from 4.49442 to 4.49364, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4936 - val_loss: 4.5332\n",
      "Epoch 172/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4925Epoch 00171: loss improved from 4.49364 to 4.49236, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4924 - val_loss: 4.5292\n",
      "Epoch 173/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4953Epoch 00172: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4952 - val_loss: 4.5201\n",
      "Epoch 174/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4944Epoch 00173: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4945 - val_loss: 4.5759\n",
      "Epoch 175/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4921Epoch 00174: loss improved from 4.49236 to 4.49224, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.4922 - val_loss: 4.5260\n",
      "Epoch 176/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4912Epoch 00175: loss improved from 4.49224 to 4.49112, saving model to weights.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254016/254016 [==============================] - 22s - loss: 4.4911 - val_loss: 4.5361\n",
      "Epoch 177/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4919Epoch 00176: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4920 - val_loss: 4.5188\n",
      "Epoch 178/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4944Epoch 00177: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4947 - val_loss: 4.5736\n",
      "Epoch 179/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4936Epoch 00178: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4935 - val_loss: 4.5165\n",
      "Epoch 180/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4926Epoch 00179: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4923 - val_loss: 4.5263\n",
      "Epoch 181/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4890Epoch 00180: loss improved from 4.49112 to 4.48882, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4888 - val_loss: 4.5495\n",
      "Epoch 182/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4895Epoch 00181: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4898 - val_loss: 4.5584\n",
      "Epoch 183/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4928Epoch 00182: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4927 - val_loss: 4.5189\n",
      "Epoch 184/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4896Epoch 00183: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4901 - val_loss: 4.5238\n",
      "Epoch 185/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4924Epoch 00184: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4923 - val_loss: 4.5216\n",
      "Epoch 186/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4919Epoch 00185: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4915 - val_loss: 4.5197\n",
      "Epoch 187/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4904Epoch 00186: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4903 - val_loss: 4.5252\n",
      "Epoch 188/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4894Epoch 00187: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4897 - val_loss: 4.5177\n",
      "Epoch 189/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4906Epoch 00188: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4905 - val_loss: 4.5574\n",
      "Epoch 190/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4886Epoch 00189: loss improved from 4.48882 to 4.48860, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.4886 - val_loss: 4.5154\n",
      "Epoch 191/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4915Epoch 00190: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4921 - val_loss: 4.5161\n",
      "Epoch 192/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4880Epoch 00191: loss improved from 4.48860 to 4.48787, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4879 - val_loss: 4.5499\n",
      "Epoch 193/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4912Epoch 00192: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4911 - val_loss: 4.5197\n",
      "Epoch 194/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4875Epoch 00193: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4880 - val_loss: 4.5165\n",
      "Epoch 195/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4890Epoch 00194: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4890 - val_loss: 4.5203\n",
      "Epoch 196/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4888Epoch 00195: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4888 - val_loss: 4.5168\n",
      "Epoch 197/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4879Epoch 00196: loss improved from 4.48787 to 4.48760, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4876 - val_loss: 4.6423\n",
      "Epoch 198/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4910Epoch 00197: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4905 - val_loss: 4.5287\n",
      "Epoch 199/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4891Epoch 00198: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4888 - val_loss: 4.5493\n",
      "Epoch 200/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4876Epoch 00199: loss improved from 4.48760 to 4.48749, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4875 - val_loss: 4.5461\n",
      "Epoch 201/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4877Epoch 00200: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4881 - val_loss: 4.5262\n",
      "Epoch 202/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4881Epoch 00201: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4878 - val_loss: 4.5134\n",
      "Epoch 203/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4895Epoch 00202: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4889 - val_loss: 4.5188\n",
      "Epoch 204/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4853Epoch 00203: loss improved from 4.48749 to 4.48570, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4857 - val_loss: 4.5117\n",
      "Epoch 205/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4869Epoch 00204: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4867 - val_loss: 4.5235\n",
      "Epoch 206/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4880Epoch 00205: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4884 - val_loss: 4.5294\n",
      "Epoch 207/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4871Epoch 00206: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4870 - val_loss: 4.5397\n",
      "Epoch 208/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4891Epoch 00207: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4889 - val_loss: 4.5161\n",
      "Epoch 209/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4876Epoch 00208: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4877 - val_loss: 4.5598\n",
      "Epoch 210/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4867Epoch 00209: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4870 - val_loss: 4.5171\n",
      "Epoch 211/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4842Epoch 00210: loss improved from 4.48570 to 4.48434, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4843 - val_loss: 4.5243\n",
      "Epoch 212/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4853Epoch 00211: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4851 - val_loss: 4.5219\n",
      "Epoch 213/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4871Epoch 00212: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4870 - val_loss: 4.5469\n",
      "Epoch 214/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4867Epoch 00213: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254016/254016 [==============================] - 22s - loss: 4.4867 - val_loss: 4.5333\n",
      "Epoch 215/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4839Epoch 00214: loss improved from 4.48434 to 4.48325, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.4832 - val_loss: 4.5125\n",
      "Epoch 216/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4860Epoch 00215: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4864 - val_loss: 4.5159\n",
      "Epoch 217/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4858Epoch 00216: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4858 - val_loss: 4.5178\n",
      "Epoch 218/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4885Epoch 00217: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4881 - val_loss: 4.5150\n",
      "Epoch 219/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4834Epoch 00218: loss improved from 4.48325 to 4.48306, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.4831 - val_loss: 4.5175\n",
      "Epoch 220/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4860Epoch 00219: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4861 - val_loss: 4.5117\n",
      "Epoch 221/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4851Epoch 00220: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4848 - val_loss: 4.5224\n",
      "Epoch 222/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4851Epoch 00221: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4856 - val_loss: 4.5176\n",
      "Epoch 223/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4884Epoch 00222: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4880 - val_loss: 4.5239\n",
      "Epoch 224/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4839Epoch 00223: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4837 - val_loss: 4.5299\n",
      "Epoch 225/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4828Epoch 00224: loss improved from 4.48306 to 4.48244, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4824 - val_loss: 4.5246\n",
      "Epoch 226/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4875Epoch 00225: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4869 - val_loss: 4.5080\n",
      "Epoch 227/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4848Epoch 00226: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4849 - val_loss: 4.5159\n",
      "Epoch 228/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4819Epoch 00227: loss improved from 4.48244 to 4.48169, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4817 - val_loss: 4.5451\n",
      "Epoch 229/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4830Epoch 00228: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4834 - val_loss: 4.5407\n",
      "Epoch 230/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4854Epoch 00229: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4850 - val_loss: 4.5071\n",
      "Epoch 231/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4833Epoch 00230: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4832 - val_loss: 4.5161\n",
      "Epoch 232/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4837Epoch 00231: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4839 - val_loss: 4.5327\n",
      "Epoch 233/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4836Epoch 00232: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4837 - val_loss: 4.6199\n",
      "Epoch 234/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4882Epoch 00233: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4881 - val_loss: 4.5075\n",
      "Epoch 235/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4837Epoch 00234: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4837 - val_loss: 4.5178\n",
      "Epoch 236/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4812Epoch 00235: loss improved from 4.48169 to 4.48106, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 21s - loss: 4.4811 - val_loss: 4.5199\n",
      "Epoch 237/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4828Epoch 00236: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4828 - val_loss: 4.5123\n",
      "Epoch 238/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4838Epoch 00237: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4842 - val_loss: 4.5080\n",
      "Epoch 239/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4828Epoch 00238: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4826 - val_loss: 4.5279\n",
      "Epoch 240/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4834Epoch 00239: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4834 - val_loss: 4.5169\n",
      "Epoch 241/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4851Epoch 00240: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4854 - val_loss: 4.5118\n",
      "Epoch 242/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4829Epoch 00241: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4829 - val_loss: 4.5259\n",
      "Epoch 243/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4809Epoch 00242: loss improved from 4.48106 to 4.48074, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4807 - val_loss: 4.5479\n",
      "Epoch 244/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4832Epoch 00243: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4830 - val_loss: 4.5231\n",
      "Epoch 245/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4811Epoch 00244: loss improved from 4.48074 to 4.48071, saving model to weights.best.hdf5\n",
      "254016/254016 [==============================] - 22s - loss: 4.4807 - val_loss: 4.5108\n",
      "Epoch 246/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4828Epoch 00245: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4833 - val_loss: 4.5203\n",
      "Epoch 247/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4841Epoch 00246: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4836 - val_loss: 4.5172\n",
      "Epoch 248/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4813Epoch 00247: loss did not improve\n",
      "254016/254016 [==============================] - 21s - loss: 4.4810 - val_loss: 4.5245\n",
      "Epoch 249/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4836Epoch 00248: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4834 - val_loss: 4.5122\n",
      "Epoch 250/250\n",
      "253440/254016 [============================>.] - ETA: 0s - loss: 4.4840Epoch 00249: loss did not improve\n",
      "254016/254016 [==============================] - 22s - loss: 4.4835 - val_loss: 4.5139\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', patience=10, factor=0.1, min_lr=0.00001)\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='loss', patience=20, verbose=1), reduce_lr, checkpoint]\n",
    "\n",
    "results = model.fit(X_train, Y_train, batch_size=512, epochs=250, validation_split = 0.2, shuffle = True, callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b7a3646c080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAHwCAYAAABdWe3bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xl8XHW9//HXd7bsbbqkG6ULtLTQhRZbBLHsCiroBUVEEAEFQQXxKoILF/SCInr151UEkUVR5IIsbkUWoVB2aUuhLVCW0n1Ll6Rpttm+vz++ZyaTNEknbTLTnPN+Ph55TDI5c87JsLzn+/luxlqLiIiI9E+hYt+AiIiI7DkFuYiISD+mIBcREenHFOQiIiL9mIJcRESkH1OQi4iI9GMKcpEAMsb80xjz+WLfh4jsPaN55CKFY4xZCXzRWvuvYt+LiPiDWuQiPmOMiRT7HvaWH/4GkUJRkIvsI4wxpxhjFhtj6owxzxtjpuf87ipjzLvGmAZjzOvGmNNyfneeMeY5Y8zPjTFbgWu95541xvzUGLPdGPOeMeYjOa95yhjzxZzXd3fseGPMfO/a/zLG3GSM+WM3f8cnvL9jh3fPJ3vPrzTGnJhz3LWZ8xhjxhljrDHmC8aY1cCTXvn/qx3O/aox5nTv+8nGmMeNMduMMcuNMZ/e83dfpP9SkIvsA4wxM4E7gC8BQ4DfAH8zxpR4h7wLzAEGAt8H/miMGZlzivcDK4DhwPU5zy0HhgI3ArcbY0wXt9DdsX8C/u3d17XA57r5Ow4H7gKuAKqBo4GVu/v7cxwDHAycBNwDnJVz7kOAscBcY0wF8Lh3b8OAzwC/9o4RCRQFuci+4SLgN9bal6y1KWvt74FW4AgAa+2frbXrrbVpa+29wNvA4TmvX2+t/aW1NmmtbfaeW2Wt/a21NgX8HhiJC/rOdHqsMWYMMBv4L2tt3Fr7LPC3bv6OLwB3WGsf9+51nbX2zR68D9daaxu9v+EhYIYxZqz3u7OBB621rcApwEpr7Z3e3/wK8ABwRg+uJeILCnKRfcNY4BteWb3OGFMH7A+MAjDGnJtTdq8DpuJazxlrOjnnxsw31tom79vKLq7f1bGjgG05z3V1rYz9cdWDPZU9t7W2AZiLa22Da53f7X0/Fnh/h/frbGDEXlxbpF/SgBKRfcMa4Hpr7fUdf+G1SH8LnAC8YK1NGWMWA7ll8r6afrIBGGyMKc8J8/27OX4NcGAXv2sEynN+7ix0O/4d9wDXGGPmA6XAvJzrPG2t/VB3Ny8SBGqRixRe1BhTmvMVwQX1xcaY9xunwhjzMWNMFVCBC7haAGPM+bgWeZ+z1q4CFuAG0MWMMUcCp3bzktuB840xJxhjQsaY/Ywxk73fLQY+Y4yJGmNmAZ/K4xYexrW+fwDca61Ne8//AzjIGPM573xRY8xsY8zBe/J3ivRnCnKRwnsYaM75utZauwC4EPgVsB14BzgPwFr7OvA/wAvAJmAa8FwB7/ds4EhgK3AdcC+u/34X1tp/A+cDPwfqgadxQQxwNa61vh03YO9Pu7uw1x/+IHBi7vFe2f3DuLL7elzXwI+Bkk5OI+JrWhBGRHrEGHMv8Ka19ppi34uIqEUuIrvhlawP9ErlJwOfAP5S7PsSEUeD3URkd0bgyttDgLXAJd50LxHZB6i0LiIi0o+ptC4iItKPKchFRET6sX7RRz506FA7bty4Yt+GiIhIQSxcuHCLtbYmn2P7RZCPGzeOBQsWFPs2RERECsIYsyrfY1VaFxER6ccU5CIiIv2YglxERKQf6xd95CIiUliJRIK1a9fS0tJS7FvxtdLSUkaPHk00Gt3jcyjIRURkF2vXrqWqqopx48ZhjNn9C6THrLVs3bqVtWvXMn78+D0+j0rrIiKyi5aWFoYMGaIQ70PGGIYMGbLXVQ8FuYiIdEoh3vd64z1WkIuIyD6psrKy2LfQLyjIRURE+rE+C3JjzB3GmM3GmKU5z/3EGPOmMeY1Y8xDxpjqvrq+iIj4g7WWK664gqlTpzJt2jTuvfdeADZs2MDRRx/NjBkzmDp1Ks888wypVIrzzjsve+zPf/7zIt993+vLUeu/A34F3JXz3OPAt621SWPMj4FvA1f24T2IiMhe+v7fl/H6+h29es5DRg3gmlOn5HXsgw8+yOLFi3n11VfZsmULs2fP5uijj+ZPf/oTJ510Et/97ndJpVI0NTWxePFi1q1bx9Klrg1ZV1fXq/e9L+qzFrm1dj6wrcNzj1lrk96PLwKj++r6IiLiD88++yxnnXUW4XCY4cOHc8wxx/Dyyy8ze/Zs7rzzTq699lqWLFlCVVUVBxxwACtWrODSSy/lkUceYcCAAcW+/T5XzHnkFwD3dvVLY8xFwEUAY8aMKdQ9iYhIB/m2nAvt6KOPZv78+cydO5fzzjuP//zP/+Tcc8/l1Vdf5dFHH+WWW27hvvvu44477ij2rfapogx2M8Z8F0gCd3d1jLX2VmvtLGvtrJqavHZyExERH5ozZw733nsvqVSK2tpa5s+fz+GHH86qVasYPnw4F154IV/84hdZtGgRW7ZsIZ1O88lPfpLrrruORYsWFfv2+1zBW+TGmPOAU4ATrLW20NcXEZH+5bTTTuOFF17g0EMPxRjDjTfeyIgRI/j973/PT37yE6LRKJWVldx1112sW7eO888/n3Q6DcCPfvSjIt993zN9maXGmHHAP6y1U72fTwZ+Bhxjra3N9zyzZs2y2o9cRKRw3njjDQ4++OBi30YgdPZeG2MWWmtn5fP6vpx+dg/wAjDJGLPWGPMF3Cj2KuBxY8xiY8wtfXX9rrQkUtQ3JQp9WRERkT7RZ6V1a+1ZnTx9e19dL183zXuHX817h/d+9LFi34qIiMheC9zKbgZQz7yIiPhF8ILcW6Be4+xERMQPAhjk7lE5LiIifhC8IMdrkRf5PkRERHpD8II82yJXlIuISP8XuCAPeUGeVo6LiPhGd3uXr1y5kqlTpxbwbgorcEGeHeym4rqIiPhAMTdNKSpV1kVE8vTPq2Djkt4954hp8JEbuvz1VVddxf77789XvvIVAK699loikQjz5s1j+/btJBIJrrvuOj7xiU/06LItLS1ccsklLFiwgEgkws9+9jOOO+44li1bxvnnn088HiedTvPAAw8watQoPv3pT7N27VpSqRRXX301Z5555l792X0hcEEeynSSi4jIPuvMM8/k8ssvzwb5fffdx6OPPspll13GgAED2LJlC0cccQQf//jHs5XWfNx0000YY1iyZAlvvvkmH/7wh3nrrbe45ZZb+NrXvsbZZ59NPB4nlUrx8MMPM2rUKObOnQtAfX19n/yteytwQW6yfeRqkouI5KWblnNfmTlzJps3b2b9+vXU1tYyaNAgRowYwde//nXmz59PKBRi3bp1bNq0iREjRuR93meffZZLL70UgMmTJzN27FjeeustjjzySK6//nrWrl3L6aefzsSJE5k2bRrf+MY3uPLKKznllFOYM2dOX/25eyV4feTeo3JcRGTfdsYZZ3D//fdz7733cuaZZ3L33XdTW1vLwoULWbx4McOHD6elpaVXrvXZz36Wv/3tb5SVlfHRj36UJ598koMOOohFixYxbdo0vve97/GDH/ygV67V2wLXIg8ZzSMXEekPzjzzTC688EK2bNnC008/zX333cewYcOIRqPMmzePVatW9ficc+bM4e677+b444/nrbfeYvXq1UyaNIkVK1ZwwAEHcNlll7F69Wpee+01Jk+ezODBgznnnHOorq7mtttu64O/cu8FLshVWhcR6R+mTJlCQ0MD++23HyNHjuTss8/m1FNPZdq0acyaNYvJkyf3+Jxf/vKXueSSS5g2bRqRSITf/e53lJSUcN999/GHP/yBaDTKiBEj+M53vsPLL7/MFVdcQSgUIhqNcvPNN/fBX7n3+nQ/8t7Sm/uR3/bMCq6b+wavXvNhBpZFe+WcIiJ+o/3IC2ef3Y98X5Udtb7vf34RERHZLZXWRUTEF5YsWcLnPve5ds+VlJTw0ksvFemOCiN4Qe49KsZFRPxl2rRpLF68uNi3UXDBK62HtB+5iIj4R+CCPNMi16YpIiLiB4ELcrRpioiI+EjggjykTnIRkX1eb209+tRTT/H888/3wh3t/jqnnHLKXh+zJwIX5MYrrqu0LiLSS268EebNa//cvHnu+SIrVJAXU/CCPDuNXEkuItIrZs+GT3+6LcznzXM/z569V6dNJpOcffbZHHzwwXzqU5+iqakJgIULF3LMMcfwvve9j5NOOokNGzYA8L//+78ccsghTJ8+nc985jOsXLmSW265hZ///OfMmDGDZ555pt35r732Wj7/+c8zZ84cxo4dy4MPPsi3vvUtpk2bxsknn0wikQDgiSeeYObMmUybNo0LLriA1tZWAB555BEmT57MYYcdxoMPPpg9b2NjIxdccAGHH344M2fO5K9//etevQ+7E7jpZ5nSugati4jk6fLLYXfTukaNgpNOgpEjYcMGOPhg+P733VdnZsyA//f/uj3l8uXLuf322znqqKO44IIL+PWvf83XvvY1Lr30Uv76179SU1PDvffey3e/+13uuOMObrjhBt577z1KSkqoq6ujurqaiy++mMrKSr75zW92eo13332XefPm8frrr3PkkUfywAMPcOONN3Laaacxd+5cTj75ZM477zyeeOIJDjroIM4991xuvvlmLr74Yi688EKefPJJJkyY0G6f8uuvv57jjz+eO+64g7q6Og4//HBOPPHE7t+/vRC8Fnm2tK4kFxHpNYMGuRBfvdo9Dhq016fcf//9OeqoowA455xzePbZZ1m+fDlLly7lQx/6EDNmzOC6665j7dq1AEyfPp2zzz6bP/7xj0Qi+bVTP/KRjxCNRpk2bRqpVIqTTz4ZcHPSV65cyfLlyxk/fjwHHXQQAJ///OeZP38+b775JuPHj2fixIkYYzjnnHOy53zssce44YYbmDFjBsceeywtLS2sXr16r9+PrgSuRY5a5CIiPbObljPQVk6/+mq4+Wa45ho47ri9uqzJ9IXm/GytZcqUKbzwwgu7HD937lzmz5/P3//+d66//nqWLFmy22uUlJQAZDdGyVwzFAqRTCb36L6ttTzwwANMmjSp3fObNm3ao/PtTuBa5KEO/2KIiMheyoT4fffBD37gHnP7zPfQ6tWrs4H9pz/9iQ9+8INMmjSJ2tra7POJRIJly5aRTqdZs2YNxx13HD/+8Y+pr69n586dVFVV0dDQsMf3MGnSJFauXMk777wDwB/+8AeOOeYYJk+ezMqVK3n33XcBuOeee7KvOemkk/jlL3+ZXXjslVde2ePr5yNwQd62IIya5CIiveLll114Z1rgxx3nfn755b067aRJk7jppps4+OCD2b59O5dccgmxWIz777+fK6+8kkMPPZQZM2bw/PPPk0qlOOecc5g2bRozZ87ksssuo7q6mlNPPZWHHnqo08Fu+SgtLeXOO+/kjDPOYNq0aYRCIS6++GJKS0u59dZb+djHPsZhhx3GsGHDsq+5+uqrSSQSTJ8+nSlTpnD11Vfv1fuwO4HbxvTBRWv5z/te5alvHsu4oRW9ck4REb/RNqaFo21MeyiUXdlNRESk/wtckGsbUxER8ZPABXmGclxERPwgcEHeNp1BSS4i0p3+MIaqv+uN9zhwQa6V3UREdq+0tJStW7cqzPuQtZatW7dSWlq6V+cJ3IIw2jRFRGT3Ro8ezdq1a6mtrS32rfhaaWkpo0eP3qtzBC/ItWmKiMhuRaNRxo8fX+zbkDyotC4iItKPBS7I0aYpIiLiI4ELcqMWuYiI+EjgglybpoiIiJ8ELsi1aYqIiPhJ8IJcpXUREfGRwAW5Nk0RERE/CVyQo01TRETER/osyI0xdxhjNhtjluY8d4YxZpkxJm2MyWuf1V6/L+9ROS4iIn7Qly3y3wEnd3huKXA6ML8Pr9utkDZNERERH+mzJVqttfONMeM6PPcG5O5AVnht+5EX7RZERER6TeD6yDObpqi0LiIifrDPBrkx5iJjzAJjzILe3H2nba11JbmIiPR/+2yQW2tvtdbOstbOqqmp6b0Tq7QuIiI+ss8GeV/JltY12E1ERHygL6ef3QO8AEwyxqw1xnzBGHOaMWYtcCQw1xjzaF9dvyshDVoXEREf6ctR62d18auH+uqa+ciMmFdpXURE/CB4pfXMYDc1yUVExAcCF+QhbZoiIiI+Erggzwxb11rrIiLiB4EL8rbSuoiISP8XvCDPfKMkFxERHwhckIeMSusiIuIfgQtyo8FuIiLiI8EL8uzKbiIiIv1f8IJcm6aIiIiPBDbItbKbiIj4QfCCHC22LiIi/hG4IA95f7Eq6yIi4geBC3KDNk0RERH/CF6Qa9MUERHxkcAFuTZNERERPwlckGvTFBER8ZPABbkxuz9GRESkvwhckGfWWleDXERE/CBwQZ5pkKu0LiIifhC8INdgNxER8ZHABXm2tF7k+xAREekNgQvyDJXWRUTEDwIX5EZLrYuIiI8ELsjbSutKchER6f8CF+TaxlRERPwkeEGO5pGLiIh/BC7IQ9o0RUREfCRwQY5K6yIi4iOBC/JMaV21dRER8YPgBXm2tC4iItL/BS7IM9PP0qqti4iIDwQuyLUejIiI+Enwglxd5CIi4iMBDHJtmiIiIv4RwCB3j1ZNchER8YHgBbn3qBwXERE/CFyQa9MUERHxk8AFuTZNERERPwlekGvTFBER8ZHgBbk2TRERER8JbpArx0VExAeCF+TZ0rqSXERE+r/ABXlILXIREfGRwAV5ZmU3jVoXERE/6LMgN8bcYYzZbIxZmvPcYGPM48aYt73HQX11/S7vy3vUYDcREfGDvmyR/w44ucNzVwFPWGsnAk94PxeUBruJiIif9FmQW2vnA9s6PP0J4Pfe978H/qOvrt+V7KYpSnIREfGBQveRD7fWbvC+3wgML/D1AdcqV4yLiIgfFG2wm3VN4i7z1BhzkTFmgTFmQW1tba9eO2SMSusiIuILhQ7yTcaYkQDe4+auDrTW3mqtnWWtnVVTU9OrN2GAtJJcRER8oNBB/jfg8973nwf+WuDrAyqti4iIf/Tl9LN7gBeAScaYtcaYLwA3AB8yxrwNnOj9XHBGpXUREfGJSF+d2Fp7Vhe/OqGvrpkvg0ati4iIPwRuZTdQaV1ERPwjmEGOUYtcRER8IZBBHjJaa11ERPwhkEGuwW4iIuIXwQxytGmKiIj4QzCD3GjTFBER8YeABrkGu4mIiD8ENMg1/UxERPwhkEGuTVNERMQvAhnk2jRFRET8IphBrtK6iIj4RECDXKV1ERHxh2AGOdo0RURE/CGYQa555CIi4hOBDPKQMVrZTUREfCGQQe5GrRf7LkRERPZeMINcg91ERMQnAhrk2jRFRET8IbhBrhwXEREfCGaQo01TRETEHwIZ5CGt7CYiIj4RyCA3xmjUuoiI+EIwgxyt7CYiIv4QzCBXaV1ERHwioEGuwW4iIuIPwQxyNP1MRET8IZhBrnnkIiLiE4EM8pAxpJXkIiLiA4EMctBgNxER8YdABrk2TREREb8IZJCHjOaRi4iIPwQyyDWPXERE/CKYQa5NU0RExCcCGeTaNEVERPwikEGONk0RERGfCGSQa9MUERHxi0AGecgU+w5ERER6RyCD3GhlNxER8YlgBjlaa11ERPwhkEEe0spuIiLiE4EMcgwqrYuIiC8EMsgNmkcuIiL+EMggD2mNVhER8YlABrlRaV1ERHyiKEFujPmaMWapMWaZMebywl9fDXIREfGHgge5MWYqcCFwOHAocIoxZkIh78GNWleUi4hI/1eMFvnBwEvW2iZrbRJ4Gji90DehtdZFRMQPihHkS4E5xpghxphy4KPA/oW8AWOMSusiIuILkUJf0Fr7hjHmx8BjQCOwGEh1PM4YcxFwEcCYMWN69R5CWtpNRER8oiiD3ay1t1tr32etPRrYDrzVyTG3WmtnWWtn1dTU9Or1DSqti4iIPxS8RQ5gjBlmrd1sjBmD6x8/osDXx6q4LiIiPlCUIAceMMYMARLAV6y1dYW8uCrrIiLiF0UJcmvtnGJcN8NtY1rMOxAREekdgV3ZTfPIRUTED4IZ5MW+ARERkV4SyCAPGaO11kVExBcCGeSutF7suxAREdl7wQ3yYt+EiIhILwhokKu0LiIi/hDMIAc1yUVExBeCGeTaNEVERHwikEEe0jxyERHxiUAGuTZNERERvwhmkGvTFBER8YmABrnmkYuIiD8EM8gxCnIREfGFYAa5BruJiIhPBDLIQ1rZTUREfCKQQW7Qym4iIuIPwQxyDXYTERGfCGiQa2U3ERHxh4AGuQa7iYiIPwQzyFFpXURE/CGQQR5SaV1ERHwikEFuDBq1LiIivhDMIEeldRER8YdgBrkxGuwmIiK+ENAgV4tcRET8IZhBjga7iYiIPwQzyDWPXEREfCKQQR4ykFaOi4iIDwQyyN0SrUpyERHp/4IZ5Giwm4iI+EMwg9wYBbmIiPhCXkFujPmaMWaAcW43xiwyxny4r2+urxiDSusiIuIL+bbIL7DW7gA+DAwCPgfc0Gd31cdUWhcREb/IN8iN9/hR4A/W2mU5z/U72jRFRET8It8gX2iMeQwX5I8aY6qAdN/dVt/SpikiIuIXkTyP+wIwA1hhrW0yxgwGzu+72+pbKq2LiIhf5NsiPxJYbq2tM8acA3wPqO+72+pbxrheAa3uJiIi/V2+QX4z0GSMORT4BvAucFef3VUf83JcrXIREen38g3ypHXN108Av7LW3gRU9d1t9S3jjdNTjouISH+Xbx95gzHm27hpZ3OMMSEg2ne31bdC2Ra5pR8PvhcREcm7RX4m0IqbT74RGA38pM/uqo9lSuvaOEVERPq7vILcC++7gYHGmFOAFmttP+4jz5TWleQiItK/5btE66eBfwNnAJ8GXjLGfKovb6wvabCbiIj4Rb595N8FZltrNwMYY2qAfwH399WN9aXsYDcFuYiI9HP59pGHMiHu2dqD1+5zsi1yldZFRKSfy7dF/ogx5lHgHu/nM4GH9/SixpivA1/EzQBbApxvrW3Z0/P1VEildRER8Yl8B7tdAdwKTPe+brXWXrknFzTG7AdcBsyy1k4FwsBn9uRceypTWtd66yIi0t/l2yLHWvsA8EAvXrfMGJMAyoH1vXTevLSV1kVERPq3boPcGNNA53nn9h2xdkBPL2itXWeM+SmwGmgGHrPWPtbJtS8CLgIYM2ZMTy+T5730yWlFREQKptvSurW2ylo7oJOvqj0JcQBjzCDcUq/jgVFAhbcRS8dr32qtnWWtnVVTU7Mnl+pSSJumiIiITxRj5PmJwHvW2lprbQJ4EPhAIW9A88hFRMQvihHkq4EjjDHlxi2xdgLwRiFvILO6unJcRET6u4IHubX2JdxCMotwU89CuBHxBRMKadS6iIj4Q96j1nuTtfYa4JpiXBtyWuTKcRER6ef67epse0WbpoiIiE8EMsi1spuIiPhFIINcm6aIiIhfBDPItWmKiIj4RCCDPFNaTyvHRUSknwtkkLeV1pXkIiLSvwUyyNFgNxER8YlABnlmrXUREZH+LpBBnolxrewmIiL9XTCDXKV1ERHxiUAGeXYb0yLfh4iIyN4KZJCb7PQzRbmIiPRvgQzyDOW4iIj0d4EM8rZR60pyERHp3wIZ5EYru4mIiE8EM8i1aYqIiPhEIIM8pE1TRETEJwIZ5NnSerq49yEiIrK3AhnkmbXd1CIXEZH+LpBBrpXdRETELwIZ5NmV3RTkIiLSzwUyyNtmkSvJRUSkfwtmkKu0LiIiPhHIIM+U1rXWuoiI9HeBDHKy88hFRET6t0AGebaPXEkuIiL9XCCDvG3UupJcRET6t0AGuVFpXUREfCKYQa5NU0RExCcCGeSh7DamSnIREenfAhnkaB65iIj4RCCD3GjTFBER8YlABnmobY1WERGRfi2QQW6yK7sV+UZERET2UkCD3D2qtC4iIv1dIIM8pMFuIiLiE4EM8sywdU0/ExGR/i6QQa6V3URExC8CGeQhJbmIiPhEIIM8M/tMpXUREenvghnkGuwmIiI+Ecggz25jWuT7EBER2VuBDPIMldZFRKS/C2SQq7QuIiJ+UfAgN8ZMMsYszvnaYYy5vKD3gBZbFxERf4gU+oLW2uXADABjTBhYBzxUyHsIeR9ftNa6iIj0d8UurZ8AvGutXVXIi2a3MVWQi4hIP1fsIP8McE+hL6pNU0RExC+KFuTGmBjwceDPXfz+ImPMAmPMgtra2l69dmbTFJXWRUSkvytmi/wjwCJr7abOfmmtvdVaO8taO6umpqaXL50prSvJRUSkfytmkJ9FEcrq0FZaFxER6e+KEuTGmArgQ8CDxbh+ZmU3LQgjIiL9XcGnnwFYaxuBIcW4NrRtmqIcFxGR/q7Yo9aLQiu7iYiIXwQyyItSWq9bo08OIiLS6wIZ5BkFi9W6NfCL6fDe/PyOn/9TeO4XfXtPIiLiC4EMclPopdabt4FNQ2Oe8+GX/xPefrxv70lERHwhkEFe8NJ6Ouk9pvI/Pt9jRUQk0AIZ5G1LtBZIKhPkyfyOTyfzP1ZERAItmEFe6E1T0j0M8lRCQS4iInkJZJCHCr1pSjrhPfagRW5VWhcRkd0LZJBT6E1TetxHnlAfuYiI5CWQQZ4prRestp4J5bxL6130ke9YD78+EurX9d69iYhIvxbIIA8VfLDbHpTWOzu2djlsfh22vNV79yYiIv1aIIPcZKafFaq2ni2tJ/I8vovBbj0t0YuIiO8FM8i9x4K1yHsawKku5pH3tGUvIiK+F8ggzywIs89OP+uqtJ6K9+w8IiLie4EM8rZR64Uurecb5LsrrSvIRUTECWSQZ9daL5SeBLC1XS/Rqha5iIh0EMwg9x4LVlrP9m3n0UeenaqmPnIREdm9QAZ54TdN6cE88u5WgVOLXEREOghkkBd805SeLNHaXatbfeQiItJBMIN8X940pbtjVVoXEZEOghnk+/Ko9cwxNrXrJ41saV0LwoiIiBPoIC+YzH7kqR6U1mHXwFZpXUREOghmkGdL6/twixx23co00yJP5bnUq4iI+F4ggzylHBVdAAAgAElEQVRUtG1MexjkHY9XH7mIiHQQyCA3+/ISre1K6x2O16YpIiLSQTCD3Hu0hZqA1pMAbtci76K0rha5iIh4ghnkhS6t96Qknu6mRa7SuoiIdBDQIM+sCLMPDnZLqY9cRETyF8ggB9cqL9zKbj1ZorWbIO/JCnEiIhIIgQ3ykDF7tiCMtfDOE5BO5/+adE82TelmHrla5CIi0kFgg9ywh5X1Da/CH0+H957O/zXZ0noe87+7WxBGQS4iIh0EN8j3tLTetMU9ttTl/5oezSPPCW+V1kVEZDcCHORmz1rkrQ3uMdGS/2tSPQny7kata611ERFpL7hBzh4u0ZoJ8mRz/q/pyTzy7haEya7ZriVaRUTECW6Q72lpPdsi35Mg7+mo9Y6bpqi0LiIi7QUzyK3lstCfOWD78z1/7R4FeU8WhOluHrlWdhMRkfaCGeQv/Iovmwc4ZNtjPX9ttrTegz7ynswjzy2b77L7mdZaFxGR9oIX5Cufg8evASCcz3SwjvakRZ7qyTxytchFRCR/wQvy9a/AkANZw3DC6XjPX1/QPnJNPxMRke4FL8g/8FX40nzqqSRs9yAQ96i0vqfbmHa1IIxGrYuIiBO8IAeIlpEgUvgWeWpvB7v1oEQvIiKBEMwgB+JECdsC9ZH3qLTezTxyldZFRKSDwAZ5cm9b5Hu0IIy2MRURkd4V2CBP7HGLfId3gr5aorWbBWEU5CIi0kFRgtwYU22Mud8Y86Yx5g1jzJGFvoe4iRLpaZBbu3ctcpva/ZZr3W5jqrXWRUSkvUiRrvsL4BFr7aeMMTGgvNA3kCDa83nkyZa2RVr2ZGU3cCEc7uZt72qtdWvbrq211kVExFPwIDfGDASOBs4DsNbGgT3orN47SSJEbA8vm2mNQ89K6x1HoncX5F1tY9rdZioiIhJYxSitjwdqgTuNMa8YY24zxlQU+iYSJopJJ7h+7uvsbM0zGDNBHq3oYWm9mz3Gdzm2i8BOxTt/XkREAq0YQR4BDgNuttbOBBqBqzoeZIy5yBizwBizoLa2ttdvImGimFSc3z7zHotWbc/vRZmBbpXDejjYLQGhqPt+dyGcSkDIa7G3+wDQTd+5iIgEVjGCfC2w1lr7kvfz/bhgb8dae6u1dpa1dlZNTU2v34QNxYjhwrGxpy3yymGQaMr/YukkRMvavu/22BQtdBL6Kq2LiEgnCh7k1tqNwBpjzCTvqROA1wt9HydN35+YSWFI97y0XlHjBp7lO+gsnYRISdv33R6boNV2E+ShqIJcRESyijVq/VLgbm/E+grg/ELfwJCBVQBESe1ZixzcyPVwtPvXpFOAhUieLfJUglZiANh0CpM9jxfk0TKttS4iIllFCXJr7WJgVjGuneW1kGMk8m6RP/jCG5wOUDncPZFohtIB3b8oE9x5t8iT2SBvaW2lLPN8KifI44153a+IiPhfYFd2I+yCtSKcYmdrfoPHNm/Z4r6p8Prs8xm5ng3yUu/n3Vwrncz2ke9oyhlQlxvkKq2LiIgnwEHuwnJgzOZdWo8mG0kShrJq90Q+I9ezAZwJ8t2X1uM2QsoadjbnBrk3/SyiIBcRkTbBDXKv1F0ds3mX1kvSjTSZ8rb+7rxa5F4LPJJnkKeTJGyIJGEam1vbPQ+0tch3t9SriIgEQnCDPOz6oQfmGeSJVJoy20QTZW1TyfJZpjUzMK0HfeRxGyZNiMbmLkrroLnkIiICBDnIvWAdGE3nVVpviqeoopmdlPcwyDv2kXd/LZuKk7BhkoRpas1pkWdK6/nORxcRkUAIbpB7LfKqaH595M3xFJU002BL20I5mUcfeW5JHHbbkk6nkqQIkSJEc2vuIjAdW+QKchERUZBTFU3TkEeQN8aTVJpm6m0PS+veXuQvrvZWgtvNIjI2lSBBhCRhmltyW+SZEr2CXERE2gQ3yL3SelUkz9J6a4oKWtiZLiEV9lrkPSitL98ab/dzV2wqQZIw1oRJJOK0JDpsXao+chERyRHcIPfmkVdGUjR2Mo/8rhdWctszK7I/N8aTlJlWmm2MFm/Blp6U1jOLvOx++lmSJCFMOEKENBvqvWuoj1xERDoR4CB388jdgjBJ0un207nuW7CGBxety/7cFE9SSpwWYjSlvWVZezBqvW0jlO5b0jadIEmEUDhC2KRYX+ddY5e+di3TKiIiQQ5yr7ReEUkD0JRoH7Ab61vY0dIWlk3xFKUkaCFGY4+C3J231fakRR4mFI4SIc2mHZkWeaa0Xp7feUREJBCCG+TeYLeykAvE3H7y1mSKLTvj7GjOCfIW1yJvJkZjErcLWQ+WaG3tbGvSLo5P2jChcJgwKZqzfeQdS+vqIxcREQU55WEXiLmLwmyqd6PFG3JK7s2tzYSMpcXGaI6nXKB2tUTr+sVtrfVUprSeZ4s87Qa7mZBrkbck0u1fl+8KcSIiEgjBDXKvtF4W8oK8pS0YN9S7ELaW7NS0eIubPtZKjMZ4ygVqZy3ylh1w2wmw+G738y4t8u5b0iadJEHY9ZGTzhm1rsFuIiKyq+AGudciLzUuKHNL69mR4pAtryda3NahLcRojifdJiid9ZE3b3ch27DR/ewFbkuefeQmnSRFmFAkQpgUrV1OP1OQi4hIkIPca5GXGheIO7sK8pYOQW5jbrpatLzzII/vdI/Nde5xlxZ596PNMy1yE4oQC6VpSXYsrXtBnlKQi4hIkIM85IK1xLhgzQ3yjfVtAb2j2T2fbHWl9RZiboR7pLTzeeStXpC31LvHzuaR//1yWPpgp7dlrBu1bsIRoibt+uPBK62bXTdfSadg07K8/2wREfGXAAd5CEJRYjml9dfX72Bna5L19S2EjDus3iutJ+Mu3JuJ0dSa9Aa7ddYib3CPLV6LPDPYLVtaT8GSP8O7T+76WmsJ2RQpwphwlKhJt1/ZLRzNzn/PBvnyf8LNR0H9ul3PJyIivhfcIAeIlBDDBW3tzjj/8evn+J/HlrOxvoXxQyuAttJ6OrdFnhns1lmQt3YsrXvzyDOl9VQc4o2dv9YL54R1g92iJqe0nkq4KkIo0u5YGjcDFpq27OGbICIi/VmwgzwcI5xOEA4Z/v3eVuLJNI8u3ciG+mYmjxgAtA12s17w2nAJTfGk6yPvrLQed33pu5bWvSBv3QnYzl/rtd6ThAmFwu1b5GmvRd4xyONN7R9FRCRQIsW+gaIKxzCpVipiYRatdi3o9d5AtwnDKjEmN8jd8yZa5lrkXY1azwx2y5TW0x3mkWeeT3QSvF44J73SeqSz0noo7B2ban+ezAcIEREJlGC3yCMxSCWoLIkQT6YZUBrJ9o3vV11GZUmEHd788kyLnEyQR7roI2/1+sg7jFrP9pFnWuqdLSaTaWWHIpiQ2zSlNZFTWg/Hclrk3uj3TJAnFOQiIkEU7CAPl0CqlcpSF46zxw3mfWMHATBiYCkDy6LZFrnxQjscK3el9dIBrnVt22+2km2Rp1pdWKfal9Ztczctcq+0bsIRCIVdizyZU1oPRVRaFxGRdoId5JESSMY5jpe5NPwg00YP5KQpIwAYPaiMQSWGz6y+Bja/gUm5FnSopNy1yAcf4MJ4x/r258wMdgMX9Dnl8qQNkW7OtMi7HuyW6QuPkGq/sls4lp02lz1WLXIRkUALeB95FFJxjo8/zYTIK7w6+occNWEoB9ZUckBNJQfEtnF43VPYFU8RSrZABMKxMnbGUzD0IHeOLW/RUDKMP7y4ii8dfSDheE6QN7cFeSgSJUWYcPN297vOlnfNlMu90elhUm1rrauPXEREOhHsFrlXWq9mB9XsZOqoKkoiYY6bPAyA4VEXtqnmemLWrXUeKSl3y7lmg/xt/rl0Izc+spxl6+vb+sgBWuqxXrm8uqKcJKGcwW6dBbkL51A44rXIc0etJ1VaFxGRXQQ7yCMxSMappoGwsQyLtV8+tSbiwjbZtINSEydlIpSVxNzWolUjIFYFW95izTYXotsa466PPBO2LXUkk16QV5a6hV5ad7jfdTbYLbOeejgKoZDXIu9YWu8Q5Cqti4gEWrCD3GuRDwt7IZgpe3sGh70gb66nlDipcCnlsYhba90YqDkItrzFai/I65oSro98wCjvfHUkEq4lP7iyjCQhwpmV3xJNuw6US2cGu7nSeogOC8LkziNPdRi1rha5iEggBTzIXYvcNG11P3cI8kEhF/CppnpKaSUdLqU8Fna7n4Err295m1VbXYhub/Ja5ANGu9+31JFMxInbMEOrSkgRbju5TbWFcUamP90rrYdsingy7fZE7xjk2T5yr0SvPnIRkUAKdpBHYtC0tW2QWYcgH4gLx2TzDkpNAhsppSIWpimRwloLQydCw3q2bnUfBLZnWuQD93MnaKknmUiQIsyQyhKSuUHuTtz+51RmYFwsO9gNoDWZ9qafRSHcsY/cC3CV1kVEAinYQR4u8dYq93QI8irrRqCnvdK6jZRRFotgLW40uTfgrbp5FQDbG+Nu05SyQRCtcKX1ZIIEYYZUxEh1fLs7DnjzPlCEMqV164K8JZHqZEGYDn3kKq2LiARSsIM8EgObbvu5Q5CXW9fKNfEGSoljoqVUlLhWdWO8beT6gcbNJd/e2Opa5LFKKKuGljpSyTgpwtRUlZCwHVrkuwS5C+dwxE0zM5kgT2aCvJNR65lzdLbAjIiI+F6wgzwca/9zxyBPuYFp4cROSolDtIyyqAvj5ngKBo0nbSJMDK2lNBqisanR9X2XVEJpNbTUk0omSRJiSEWHPnLYNci9PvNMab2tRZ5TWs8NcmvbSuu589dFRCQwAh7kJe1/ziyf6ilJuiCPJXdSauKEomVUlLggbYwnIRJja+VEZph3mTpqIK2N3qptsSooHQjNdaSTcZJEGFIZ27WPvKsWeTRTWvfWaU+kvOlnUTChtmNTCffBAVRaFxEJqGAHeSSnRV4yYJcWeSzh5nyXpZsoI04oVkZZzIVxU9wF6DslU5gZfofxg0tINHlzxEtyS+sJUoSoLo9m+8ht5m3vONgtt7Ru3HVMZlGYeBPEKty0t1DUHZs7wK2r0npLPbzxj7ZR7iIi4ivBDvJMi9yEoXosNG1r9+to3LWwQ8YyIrKTSEkFFTHXIs9sprLITqKcViazkmSzN0c81lZaT6eSJG2Y8mgEa9xrt9lKd1wXpfVIJJZdijVCmpZ4ygVyidsjnVDEBXmmFR4p67xFvvD38LMpcO/Z8Ppf9+gtEhGRfVvAg9zbgKR8CJQP2qVFTktdNuwH2XpMtIwJwyqpKolwy9Pvkk5b5jWNB+Cg+DIiSa+FXFKZLa3bZIIkYcpiYawXzlusC+Tm5p3ct2ANP3/8LYDscq7hSNvo9DAp4q1Nro+8dKA7fyjiWtiZDwIVNa6PvOMCM8/8DwwaC9FyWPPvXnnLRERk3xLsII94LfLyIW7KWG6Qp9PQsgOq93c/2xRESxlcEeO7HzuYF1ds42O/fJYF28tpKBnBmMYlVBgvWGNVrrQeb4BUCykTJhYJYb1y+VYvyJe8t5Hr/vE6tz/zDtZaEt5yrpFo26C2CCnSTd59lWZa5OH2pfWKod4CM/H2f19LPYz9AIyaCWtf7r33TURE9hnBDvJwN0HeWg9YGLh/23ORUgDOnL0/cyYO5e1NDXz7I5OpnPhBhtctphJv/fSSSheuQFXLRtJeSd164bwVF8j/fGUFlyT/wD18m3VbtpP0lnONRnNb5GlSzV7fe2m1ewxFXBk+2yJ312q3uls6Da07XCt+9CzY+BokW/fm3RIRkX2QtjEFKB/cFuTWugFlmRHs1TlBHi0DwBjDrZ+bxbamOPtVl8G/j6B06f1MDq0GYE1jiJGjZhMBhjW/wzZzoHu9F87J0iGQABLNTI+uZhorWfXE9UQa3yBuwy58s33kKdIt3mj4XfrIMy3yGveYaAIGu+/jDW6OfGm1K6+nfgEbXoP9Z/fiGygiIsUW7BZ5trTuBXk60RaOme1Gq8fkHF+a/bYsFnYhDjD+aABODrny9X/c9io3vR6DkoGEsNmSeraVXeW2SS0jziHVbqT62DdvI7bmOa5MXESobGC7FjnNXpBn+sjDUa+P3Bvglm2R5wx4a8l5zX6z3Pcqr4uI+E6wgzyzIEymtA5t5fVMEA7MCfJoeefnGXoQqarRTAi5Fd7qUyXc9eJaUvsfAYANeS1/L5wrqodhMZz3/hEMooHnQ4exunQStUddy0PpOZREw+1a5CaeKa27FnnKhHl93TZu+Nsi93ymRZ67KExukA8Y6boIFOQiIr4T7CDvONgN2oI8U1ofOLrt+Ghbi7wdY2DCCQC02ihpE2FrY5yl0alAW9+48TY8GTpkCCZaxrCSFDRtp6FiLJeU/w+bp1wAQEkklA39kEljWtuX1rc1pXh7Yx07G7yAb1da97R0aMWPngXrFuT1toiISP8R7CDvtkXeSZBHyro+1UEfAmAnpRw/eRiThlfx87ddCd14rWvjhfOwoUNcf3vrDog3UDqghrc373TLvtI+yMtCllCrNz/dC+WmJIysijBjROaDSDel9TJvgNyg8bBj/a5T1EREpF8LdpBnWuRlg9uCvGEjrFvY1iIvH+IWeIGuW+QA448hSZhGW8qRBw7lq8dP4LXkWJpNGfsNcS3paNR9cBg2ZIj7ULDDleKrBg0jnkzz1iZXGo9FQtnSelnUEkk0uEVrYhXEk2makobqEsOYKhfKO8Jeqzt3pbfM/Wda5OVD3AC5TMCLiIgvFGXUujFmJdAApICktXZWMe6D0YfDBy6FcUe1Bdw/r3Dfj5rpWsWxCiipcv3P3bTIKR3A0sgUbLyJIw8YwiGjBnDqoaPg2Sspq3At8wNHDIQtEC6tci1yL8iH1IwAYMk6dw8lkXC2RV4egWiiwfWPG8M7mxtIEWJQiaG83JKwYd6sC3M4tJ9+1rG0Xj7EPTZtbWuli4hIv1fM6WfHWWu3FPH6ECuHD1/nvs9sRtJS78Jv/SuuZG2MC/KGDd23yIE7aq7ivY1b+euIqrYnP/j17LfRzNrusQoX5NvdPuYjRowiGm5l3ptub/Tc0np5xLog9/rH39iwgwOIUBWDSGmaZmIsrU16Qd5JaT0zZS0zsr1pKww5MP/3SERE9mnBnkeeK1oGU053g9ZScfjH19tarpkw7GrUuufTx7+fuuY4oZDp/ACvXJ4Ncm8QW8mAGs4/Ksqt81cAUBrN6SMPQyzZAANcy/rNjTsYZ8KUhSFkm2kIlfLKRrfQy/rarYzKXCuzNnvmmuXe/PKmrfm/JyIiss8rVh+5BR4zxiw0xlzU2QHGmIuMMQuMMQtqa2sLc1dn3Akzz4EZ57jpWpnR4CVeCzvSfYv8gxOHcsr0UV0fkFmAJlaZXVwGgPLBXHr8BIZWuj57V1r3+sjDlpJUY7ZE/saGBmLRmNurPNFMOlLOUyt2kraGuQvfcTulAbaljnpbwd0vrfKukVNaFxER3yhWkH/QWnsY8BHgK8aYozseYK291Vo7y1o7q6amprB3F4nB5x6CU3/hfs6scR7tpo88H14rm1hl+/72ssFUlUa55tRDGDWwlCGVsew2pmURS2lqZzbI39y4g9KSWHb3s3BJOQ2taVpMCSbRyN8Wu3739Rs3sq4lxvf+spRn397SNrK9sbi9GSIi0ruKEuTW2nXe42bgIXBdvPuUoROhZpL7Ps8W+W6FIm4v8Uis7UNBpNT11QOnHjqK5799AuWxSDb0S8NQlt5JfbqMPy9Yw5adccpKS7y11hsZOKCar594EKXlVYwqT3PHc++xcNV21m/ciC0dwISaSi6/9xU2t4bd2vJqkYuI+ErBg9wYU2GMqcp8D3wYWFro++iRkl5qkc/4LHz0xvbnKhvc+bHZILeUp5uY+3YTV9z/GgBV5WXe7mfNRErK+dqJEwnFyplSE+HNjQ188ubnGWiaOGD0fvz67MPY0ZLkmr+97ga8ddhzXURE+rdiDHYbDjxkjMlc/0/W2keKcB/5ywT53rbIh09xX9AW5Jm+646yC8KkKLdN1CZL+MEnpnDcpGEMfOxPsD3lRqlnXh+rZHQlfGb2/hw0vIoJ/04RGjCEicOr+NoJE/nJo8vZMWIAA5pUWhcR8ZOCB7m1dgVwaKGvu1cmf8zNI49V9N45s0E+qPPfe4PdBppGQsbSZCr44mGjqSiJtO1Hnoq3nSdWTjjRyA1nTXc/z6/P9qtfdPQBzH1tA8vrY8yuVGldRMRPgr2yW75GToeTrndzyntLJL/SejVuPfXhw4a5EM/8Lp10a6tnpsRVDIO1C+HV/4NU0m1j6gV5NBzilENHsj5RQXqnWuQiIn6iIC+WbIu8+yCvSrtlWyeO2a/979IJV1rPVAlOut6V7R/6Eiy80z2XWdUNGD+kgm22CqvBbiIivqIgL5bdDnbzSuu4DVOmHrh/2+/CMdi+0i0okwnywePh/IehcgQs/pN7rrRtKdZxQ12Qh+M73Ih3ERHxBa3sVix5DnabXNUKG2DQoKFtvzvqa1A9FmwKDj0r5zVhOOBYeO3/3M85LfJxQyrYjjeNrmkrVI3onb9DRESKSkFeLJm+7a5K61UjoWwwJSsecz/nhDJDJ8IxV3T+ugOO7TTIy2Jh0mVDIImCXETER1RaL5bMVLauSuuxcjj2Kki2uJ9zg7w7BxzT9n2H15QO9FbIUz+5iIhvKMiLZeBot+Pa4AO6PmbWBTBkgvs+M5d9dwaMgqEHue87BPmAIV4rXMu0ioj4hoK8WPY7DK54F4ZO6PqYcBRO+w0c/S23rGu+DjjWPXbYd3zw0JEANNf3cBOaZQ/B5jd79prdSbmV6UREZO+oj7yYuuofzzV6lvvqiaMuh5GHtq0R7xkx0u3M1vr2U5TtN8W13Ctq3Pz4RLNrqQ8c3X6+/Jtz4c/nucrBl1+ESEnP7qUzdWvgrk+4cQDnz+3+2LULoXoMVBZ44xwRkX5CQe5HA/dz27F2MG5YNUvT45i68mH43cPuyVilC/P6NW6RmYFjYNxRMGK6a9E/+h0YMBq2rYAXfgVzvtF2wq3vwjtPwPvOy79isH0l/O4Ud71t77pzDDmw82Mbt8CdJ8PUT8FpN/foLegX3p3nPih97KfFvhMR6ccU5AEyZnA5hySu44RRST4zvoX9kqupbt1IRbyW0IRTiFaPJLL6Ocw7T2Bevce9qGQAnPtX+Nc18PSN8MbfoWwQDBrv5qsnm+Gdf8Gn74Jozlr0W95xx1XkTK9r3g53nwGtDfCZe+D/zoJlD8Kcb7olcDtUEHjtPrcM7duPQToNIZ/1BC243b2fc74BA0b2/fVe/6v7UDb6fX1/rb2x/BGYdx184V/t/50SkU4pyAOkNBrmoqMn8sCitTz+bAyY6n3lGgeczYjITiYNTDBw8EiGvRhn0rDLmNOYpoJmSnZsJrriaeyEEwmN/QD861r49REw5TSYcAJsXAKPfc8tG3vO/W7Fufp18MAXYNt7cO5fYNwHYcwHYMn9ULvc/c/7kmdh0Dh3G9bCK39wi980bYH1r+z7AdQT1sLql9z36xbAgFP79nrP/9L9Mxk9G774r7691t568+/u36HNy2A/H/0zF+kjCvKAueojk7ny5Emsq2umrinhvprj1DUlaGhJkkylSaTSNCdSrN3ezFtbGnls5SpaEmmgrVwfIo1ZFmbEmlJOLP8uZ7U8zEHP/YLQsz9zB0z4EGxaCrd9yK1Vv3EJpFNw+m9ciANMPR0e/ibUvgkmDI9fAzM/Bw9dBGOOhM2vwwn/BU9eB28/2jtBbm3vrpm/p7a/B42b3fdrX4aD+zDIX/+bC/HSge4DUbzJTW/cV617xT1ueFVB3tvWL4ZhB/fOWBfZZyjIA8gYw+hB5YzuYuO1jqy1bG2Ms76umfV1zdQ3J0ilYUN9M2u3N7Oh9TjOXTOTluZtHBF9iynDStlW+WH2G1jHnLW3MqJ5E9Exx7HjqO9hBo8lurOVQeUxwlNOg2d/Dod9HrDw1I9g+T+hcpgrp0fLYfYX4a1H3ddx34HmOnjpFhd8mS1hM164CV6+HcYeCUd8edffL7nffSj43ENuSduuLLoL1vwbPv7LvQv9f14FdavgrHt2/V2mNV42yA3o60uLfu9WAjz5Btedsfbl9usN7EviTVD7hvt+w6vFvRe/qV8Hvz3OfTj+4NeLfTd9y1qIN0JJZbHvpCAU5LJbxhiGVpYwtLKE6aOrOz0mnbYsXL2dua9N4ZH3trFu8QZ2tib5ofWWkF0DLH0XeNc7Jwwuj1FTeTPv2z6Y4w+s4tgBfyQUK8ec/zAkW6F1h2tFTvwwPPnf8NDFsOIpaNgAL97s+uWTra4fPhl3rc4hE1wLdPkjcOETbtpc42Y44Dj4x3+69en/+S347H2dh/T2VfDwFW4hngOPd1WDPVG/Fl7+rRtAuPolGPP+9r9f8yKUDISpn4TF97hqhbe+fq9q2ubesyO/4gYxmhCsen7fDfKNr4FNQ7hk74P85dvd15eedlM5g27Vc+69fftf/g/y1+6Ff3wdLnslEKtYKsilV4RChtnjBjN7XPspdc3xFEvW1bN2exPJtCWdtrQkUmxrjFO7M86G+mYeemUdd7+UYgD/hYmWMvCmJQyrKqGmqoRhVUsZzmw+OugDjFj+L0JVw4l+9KeYR78Dd3085wYirn/9i0/Azk1w2wlw81FuEB20bRt7+Jfg379xfcb7v9+tVx9vclvClg1yHxBMCIZMdH3/E05wv68c7gbbpdPufxLrF8HhF7nlcgE2LnV9+eOPcR8QXrzZtQpKB8Lz/wtj7naD/Ob90K3qt/I52H+2u4eXb4PNb8CIjuMVOkglIdzD/2SX/9N9mDjkP9y9jJjm/ocObvOcJ/8bxh8NE07c/bnWLYLVL7hqR1eVisatbh+Bljo3I2G/w9o29snHeq+sfsgn4PW/uA9oPVlDIde/f+ta9+8+CQedtGfn8JOVz7rHNS+51mpP/rn0N0QZkz0AABUXSURBVIvucv9Nv/skzPhsse+mzynIpU+VxcIcPn4wh4/ves58S8KF/bJ19azZ3kxtQyu1Da28tamB597ZQnMixY2pr7qD66Dq3ggTy67huPIFbCkZy8GxzXwg+W+WT7mcnW/soLE1xshDf8bs13/IhkMug8rhjF3yC+pnXETy0HMYvupFIo9f3fVNH3+1C6A/nAY3jHHPRcrcHHubclPxTAgW3AGjDnP/U9y8zB03cgZM+ggs/J1rzQ8aD/N/4srsy+e6OfRYd+z0M9v6gN9+1M2rN8b1n69+0YXuiGnuQ8Ebf3djCWZ+Dj76k/z7OF//i5uHP2qm+3nsUe6+E83wly+7WQML7oSLn/X+vnTnrde6NXD3p9zyvhXDYPoZ7X+fTrlKx8u3tX++aqQblX/g8W4tgt11Vaxb5F5z0Emw5D73N4+cvutxydb278H2la7yMPNc94Fr07K2Ev1r9xU+yJc/Au88Dh+5sX2lJZ2C+T91H1SGTS7sPa163i0J3bzNfT/xQ4W9fqHUr237sPruPAW5SCGURsOdtuZzNcdTLN/UwOvrd/Dmxh3UNSV4NT6GxtYUj21t5Kr698G6ViBTji0D/huyi9hdB48Cj86nhK9zkFlLTbiBcCRGMlzKjmSU8mQdg2w9rz4/neHVZXx0wJepZCdNkYGMtpuoSW2hghZWTDqXTTVHcdiaOxncuAJjBlB32PcwJVWMWvJrKp76ETYUZdO0iymtHsHAl27BvHwbjJhK0yk3E7IpShfcAtM+6YK+cjg88QP31VEo4lrU44+GkWe6/u63H3Oj+cGNIxg01oVfKOJCw4RdmGXm+R+Z04Ie+wF48ddw44GQaIQPXAoLf+9CurnOdSlMP9ONU0g0Q/X+rhKw6PeuBT98KjxypSvNVw5z56xf50L8zX+4NQWqx7rWXuVwt/bAw990x+33PvjYz2DUjPZ/o7XuA0XdGtdaHDXTfSACV14fOd11EexYB8OmuKlpz/0Cjv22KxG/8wQ8eKGrArTsgKMuc+MhTBgmf8zN1W9tcO9Zxw9AiRZ3j03bYPqnd723zlgLf78MGjbB6bfusoIirQ3wt69CY60bpzHrgrbfvXoPPPVD98Hti0+4fy7pFCz5s3v/Ei1wxu9237fbuMWVjo/8Cow5wj2XSrqpoAccu+u0vYZNsPVtOPY78Mz/uICrHOa6kgaOdu95T8eDLLjDfUg66/92fQ+2vuvO33FKaW+xFnZudmtgdJyWuvQB9zj6cFgxb8+mrlrrqm7DpvSLKZDGWlvse9itWbNm2QULFhT7NmQftr0x7kbdp9NUlkRIW2iMJ2lqTbnHeJLG1lT7x3iKptYk8ZSlLBqmLBYibAzvbW1i844W0taStpBIpdnRnKCuOUF9c4Ld/ScTJkWEFK24sK2OJiiJlRG3hu1NCYyBUQPLSFtLImWZFKvl0PB7jAjtoDwWwlYMo37oYQzb+hJD65fx+ohPUF99CMYYDm99kUNq52KiZSTTYOM7GdC0hmhzLelUihBpQjYFWGzFMJrHHEPzB79DefVQyqJhTKLZLfITjsH+h8O0T7nQe/AiV14vHQDL/gLphAtCm3J/VNkgOO1W9z/938xxHy5KB7rWed1q15I/8Vr4wFfbvxnWuumF7z3tKhONte5/jiMPdecsq3Zh/eY/2l5z3PdcK/6GMVAzyX34WPg7N2Yi06Ksmexa65Eyt5ZBzcFun4H35sNpt8AT33fjJY7+lltUaMhEF2SDD3RjBcYc6e7llbthy3IIRd3ffMBx8MHL3QejlnrXTTNimpt/v2MtRCtcgD31Q8C4EeCH/Ie77+r93QeQZQ/B/BvdPTZscBWezf+/vXsPkqq+Ejj+Pff2c94MMICA8hAfKAqWa0yiFvhHYjC+wsZHGeMat7JYuEm2tiw1m9rs1rpVu1u7xnLX1cLEjRuJxpjVJJYSEjRu1E3Et4AxIQpRZmAYYB4903379r1n//hdpBHGDGGgp5nzqZrq7tvD5ddnfl3nd8/93fvb6G5s9MgXXHtLfW6Ox8yz3SDknWeg+RgobHOXcS77lttndXLdM4ErnYcHlrkk1TwNlj/n7hL5wxXw6ipX/bjyu3uXSgbXpu//Gfz5Uy42W19y+9pTHZp1Llx854HXfogj6PktbHnWVYbajnPLJ99/kYvZqX8Ky77p+oSXcgPFNV9zN5s68zo476aDT+iq7qZR2ze4ZN1x8t5TAUEBvnc1fOcnMDMP19zkJsICrHkS7l4OS4+HP7keHrvBVZumLjjw/xMU3P0t2mbu3Vbqc4Ok9T9wA5wrVrmbbB0oLuIdtqtgROQlVR3RbT0tkRtzEFSVchQTVGKCMCaoRJTCmP5SSLniBhH9pZDu/oBKrPQVQ7p6iwyWI0TcTXmCMOadngJp3yPlexSCCgOlkP5iyO6hkJ2FgP5ShWzKoyWfZiDZd3yIX1UR3P/pCb4Ivu8ec2mflnRMJpenNZ9mWkNMrB6DFciVuimEsEPbmD2piWMnNjB518vMGXyFCdpLqriTPmnhZ+1X0u1NQQQmNmWY3OTmOExuztKcTTNYrrCzp5uOt1Zx/OArNBd+h5T68CtDqJemeM4t9M6+EP+dn5Nf+BmaJ3RQfPxW8utXIUE/8QlLCWadT2bzU8js8/DOXu7Og3a+AjPPIjrpIuIwIL3yXBjodB/4spWw4LNwzzmu+nDyRe5GRVued5MewSXbT/6jqxa88gD84nY3UNgveFWDGnCJ7LQrXHIs9e7/+6d8xlUM7v6YS3Z7BgoA1z0JP/4KDGxz53E9350uWXQNPHu7q8w0T3PvpxvcgCfX4krGQb9L+AOd8NEb4YWVLkk1TobfrIYTLnBXeEyaBx3zXXVgcIdLToM9cMsWNwFw9c1ujsfCq10VZO0/uAHGyRe5/6/vPVdNCAbg9e/vjVf7HHcaQ2NXcVnwWVfRaJ/jTjn5GXcTpxMvdNWPDY+6JHnG513FZ7DHfebGSW4fpX53Z8eo7AYJ4rvJad0b912lMZV3laWO+e5UU+fL0HQp/P2DcJkP194Kb2yFv7kXlmXhr+51lYnbT3anMcRzVQnx3MTTaae76sear7nJsMcsclUvxFWfSv2uzW884v4+iz7nvkCbn3PVkkrg+l77XDcY9lJuYHvmdYf0Hd2ny1kiN6a+RbHiibtioHrb5p2DbN1dpFyJyWd88hmfrt4SQ+UK01rzDJRCtvYWKUcxKU9ozqWpxMpQUGEwqT5EcUwUQxTHhLEShDFD5QpD5YjeoTI9hTIikE/7NGR8cmkf3xM2dRfoHghIeUKlalSR9oXWfJpsyidWZWehTDmKR/Q5U1Twid+vXuyRTXkElRhQpuYiuoPUPgOZjO+RTbtyaRDGlKMYETi5NeTUdBe9cZ5fx8cSA7mUR1CJGCzHpH0h78M8r5Nipp1Spp18xkdECMIIPyywoLKB2c0xcbaFnXEjs0q/ZkK8i0LDDPKU8UR5tvUitg9B72CJme15TupooCPaTmv3CzT1vMZrc5ejLTOYPrQRz89QbJrBnLe+SVnSPD/9eqbvfoGPbLqDno6z2X3iFbTMcJdKlsMKk9b9K5n+LQw2zoCwSKrcTybsJ2ycSpSfTMuu1yi3n0TPR25l4qaHmfjLfyZS6Jl7GeHir8PGx2jf+B1yQTdkm4nyk/AGdxDMPJfi4r+ldzCgtOs9UhNm0JRN0ZBJIQOd5F66h/z6hwAlapxGuncTeCniky4mnLWYoGMhpdY5yOZnaXnuNvo//lU47hza1nwJv7Qbb/oiJCqjbcdROv1aIoRM56/I/PhG2PU2msq5AUe6AR3cgXgpJNMIvVtQBJm7BNJ54v4uwvYT0GMWkZt+mkv+Gx6F9Y+4P36uzV0aOv9iWPszuOzTsEjhxRBWnAkr7nBVHCC666P4Oza6gVH7XDeI6Hpt76Bs6mlwyqXw5uPuvhdRGU5c6qoI089w1aSnboO3ngDETU7dMyA7ZpG7TLXzZfd6yqlww3Mj6vcjYYncGHNYVKKYlO8SY18xpCmbciX7qgGHqtJfrLCjUKJ7IKBQqtCUTTG5OUtbQ4Y3u/rpHgiY2Jiht1hmW19APu3RkE2RS/t09hbZWQiY3pYnqMS8u3uICQ0ZWvNpVw0JY0qViCB0g4Vc2ief9olU2dwzyFC5QiblkfE9PBFKlYiM79GUS1GJ3FUTQSWmFLpqSqkSEasbPGRTHqUw4jfbC1SieJ9/U6rERMloIp/2mdScoS2fYXPPIANBpSZ/j9EmxCgCCDkCBKXIyM8RZ3yPWHWfgd7EhhSNUubdIUF1bz8RgaktOcqlIcJyiSjdTBjpPoPAiY0ZWhvSxLGS3b2JHEW2ZufR1txAQ8anEFT43OMr+cLPH+Shxcu4Z+kKYoVYlWI5onHoXdoZ4HeZE5jW1kBbPkMlKNBe/D0NlV42ZE4jlc6iKBJH5ClSkCayKY/mXIpiGBOEEdOyJcqR0FVKE8Yxac+jvTFDGMXo0E6KmmZmxyTuu+6sUfk7uPiMPJHbZDdjzIilfHcUnE35dDQf+Lp3EaG1IU1rQ5rjO/Y/Nzq5uX5XsgujmEqk5NLe+4OXOFZ6CgGD5YhMymNiY4ZyFL8/P6MSKZqci874HhMb3YS7YhhRDCN2DQZs6wvwBDcASXlkU37y6CEClUgJKu6ui3t+ypWYcuQqN9Nac5TCmM7eIm0NGbIpjx0DAZU4xhPB94RYIahEtOTStOTTFKvmi4iIO+XiCSlfiGPcZwoq77cp43uk9zz6nmtDtOcUkzvN5Koo0JJL43tQCmO29ZdQVSY35/CSPN6WT9NbDPn9riFaclNpyqYohi5+TdkUjRmfoTDi3V1D9JfcIOm4BeeSSXnsLJTZORgwGESc37WBy19ezTOXL+fTT36PHed8grdPPQtPhEzK49j2OfgedPaW6Owt0l8KmdDaRr5jErm0xynJ6TFBEAGRVgShFEb0l0JXaWrO0ldMk04L89szZHyPIIrZVSjTmE3ROvFYfE+YMSFPrdgRuTHGmPrz9NNw+eXw8MOwZMn+r+vcwRyRH2XLSRljjBkX1q3bN2kvWeJer1tX23bVgB2RG2OMMWOMHZEbY4wx44QlcmOMMaaOWSI3xhhj6pglcmOMMaaOWSI3xhhj6pglcmOMMaaOWSI3xhhj6pglcmOMMaaOWSI3xhhj6pglcmOMMaaOWSI3xhhj6pglcmOMMaaOWSI3xhhj6pglcmOMMaaOWSI3xhhj6pglcmOMMaaOiarWug1/kIjsALaM4i4nAT2juL/xyuJ46CyGo8PieOgshqNjtOJ4nKpOHskv1kUiH20i8qKqnlnrdtQ7i+OhsxiODovjobMYjo5axNFK68YYY0wds0RujDHG1LHxmshX1roBRwmL46GzGI4Oi+OhsxiOjiMex3F5jtwYY4w5WozXI3JjjDHmqDDuErmIXCAib4nIJhG5pdbtqRcisllE3hCRV0XkxWRbu4j8VER+mzxOqHU7xxoRuU9EukVkfdW2A8ZNnDuTvvm6iJxRu5aPHcPE8O9EZGvSH18VkaVV792axPAtEflkbVo99ojITBF5WkQ2isgGEflyst364wh9SAxr2h/HVSIXER+4C/gUMB+4SkTm17ZVdWWJqi6surTiFmCtqs4D1iavzb6+DVzwgW3Dxe1TwLzk54vA3UeojWPdt9k/hgDfSPrjQlV9AiD5Pl8JnJL8m/9MvvcGKsBfq+p84GxgRRIv648jN1wMoYb9cVwlcuAsYJOqvq2qZeAh4JIat6meXQLcnzy/H7i0hm0Zk1T1f4FdH9g8XNwuAf5bnV8CbSIy7ci0dOwaJobDuQR4SFUDVX0H2IT73o97qtqlqi8nzweAN4HpWH8csQ+J4XCOSH8cb4l8OvBu1ev3+PA/gtlLgTUi8pKIfDHZNkVVu5Ln24AptWla3RkubtY/D86NScn3vqrTOhbDERCRWcAi4FdYf/yjfCCGUMP+ON4SufnjnaOqZ+DKbStE5LzqN9Vd/mCXQBwki9sf7W5gLrAQ6AL+rbbNqR8i0gT8APiKqvZXv2f9cWQOEMOa9sfxlsi3AjOrXs9Itpk/QFW3Jo/dwKO48tD2PaW25LG7di2sK8PFzfrnCKnqdlWNVDUG7mVvudJi+CFEJI1LQKtU9X+SzdYfD8KBYljr/jjeEvk6YJ6IzBaRDG4Swo9q3KYxT0QaRaR5z3PgE8B6XOyuTX7tWuCHtWlh3Rkubj8CPp/MFj4b6KsqeZoqHzhXexmuP4KL4ZUikhWR2biJWi8c6faNRSIiwLeAN1X19qq3rD+O0HAxrHV/TI32DscyVa2IyI3ATwAfuE9VN9S4WfVgCvCo68OkgO+q6moRWQc8LCLX41anu7yGbRyTRORBYDEwSUTeA74O/BMHjtsTwFLchJgh4Loj3uAxaJgYLhaRhbgy8GbgLwBUdYOIPAxsxM0wXqGqUS3aPQZ9HLgGeENEXk22fRXrjwdjuBheVcv+aHd2M8YYY+rYeCutG2OMMUcVS+TGGGNMHbNEbowxxtQxS+TGGGNMHbNEbowxxtQxS+TGHKVEJKpajelVGcXV/kRkVvVqZMaY2hlX15EbM84UVXVhrRthjDm87IjcmHFG3Nry/yJuffkXROT4ZPssEXkqWfhhrYgcm2yfIiKPishryc/Hkl35InJvsi7zGhHJJ7//pWS95tdF5KEafUxjxg1L5MYcvfIfKK1fUfVen6ouAP4DuCPZ9u/A/ap6GrAKuDPZfifwjKqeDpwB7Lkb4jzgLlU9BegFliXbbwEWJftZfrg+nDHGsTu7GXOUEpGCqjYdYPtm4HxVfTtZAGKbqk4UkR5gmqqGyfYuVZ0kIjuAGaoaVO1jFvBTVZ2XvL4ZSKvqbSKyGigAjwGPqWrhMH9UY8Y1OyI3ZnzSYZ4fjKDqecTeOTcXAnfhjt7XiYjNxTHmMLJEbsz4dEXV4/8lz5/HrQgIcDXwi+T5WuAGABHxRaR1uJ2KiAfMVNWngZuBVmC/qoAxZvTYSNmYo1e+aoUmgNWquucStAki8jruqPqqZNtfAv8lIjcBO9i72tWXgZXJ6lgRLqkPt5ylDzyQJHsB7lTV3lH7RMaY/dg5cmPGmeQc+Zmq2lPrthhjDp2V1o0xxpg6ZkfkxhhjTB2zI3JjjDGmjlkiN8YYY+qYJXJjjDGmjlkiN8YYY+qYJXJjjDGmjlkiN8YYY+rY/wPNhGJKK18M6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b79e91591d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = results.history['loss']\n",
    "val_loss = results.history['val_loss'] \n",
    "# train_acc = results.history['acc']\n",
    "# val_acc = results.history['val_acc']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9ece21380f3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# accuracy check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Prints test loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0) # accuracy check\n",
    "print(score.shape)\n",
    "print('Test loss:', score[0]) # Prints test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Serialize weights to H5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Load model and weights\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into new model\n",
    "loaded_model.load_weights(\"weights.best.hdf5\")\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b7a3674b668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b7a366e9cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b7a36cde0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 25\n",
    "test_img = X_test[k].reshape(1, 32, 32, 1)\n",
    "pred_img = model.predict(test_img)\n",
    "pred_img = pred_img.reshape(32,32)\n",
    "pred_img = pred_img.astype('int') \n",
    "\n",
    "plt.imshow(X_test[k].reshape(32,32), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(pred_img, cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(Y_test[k].reshape(32,32), cmap='gray')\n",
    "\n",
    "Y_test_img = Y_test[k].reshape(32,32)\n",
    "X_test_img = X_test[k].reshape(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (Y, X):  66.3505859375\n",
      "MSE (Y , Predict):  48.20703125\n",
      "\n",
      "MAE (Y, X):  6.2470703125\n",
      "MAE (Y , Predict):  4.884765625\n",
      "\n",
      "SSIM (Y, X):  1.0\n",
      "SSIM (Y, Predict):  1.0\n"
     ]
    }
   ],
   "source": [
    "# Compute MSE\n",
    "print('MSE (Y, X): ', mean_squared_error(Y_test_img, X_test_img))\n",
    "print('MSE (Y , Predict): ', mean_squared_error(Y_test_img, pred_img))\n",
    "\n",
    "# Compute MAE\n",
    "print('\\nMAE (Y, X): ', mean_absolute_error(Y_test_img, X_test_img))\n",
    "print('MAE (Y , Predict): ', mean_absolute_error(Y_test_img, pred_img))\n",
    "\n",
    "# Compute SSIM\n",
    "(score1, diff1) = compare_ssim(Y_test_img, X_test_img, full=True)\n",
    "print('\\nSSIM (Y, X): ', score1)\n",
    "(score2, diff2) = compare_ssim(Y_test_img, pred_img, full=True)\n",
    "print('SSIM (Y, Predict): ', score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PSNR (Y, X):  29.912355984255665\n",
      "PSNR (Y, X):  31.29969973866181\n"
     ]
    }
   ],
   "source": [
    "# Compute PSNR\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2)**2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "psnr_X_test = psnr(Y_test_img, X_test_img)\n",
    "print('\\nPSNR (Y, X): ', psnr_X_test)\n",
    "psnr_predict = psnr(Y_test_img, pred_img)\n",
    "print('PSNR (Y, X): ', psnr_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b7a3691a0b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b7a366db1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b7a366db240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "err_X_img = Y_test_img - X_test_img\n",
    "plt.imshow(err_X_img, cmap='gray')\n",
    "\n",
    "err_pred_img = Y_test_img - pred_img\n",
    "plt.figure()\n",
    "plt.imshow(err_pred_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
